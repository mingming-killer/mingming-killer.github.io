
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">

  
    <title>VR HeadTracking 分析 | Light.Moon</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="Mingming">
    
    <meta name="description" content="基本原理
VR 通过分屏渲染一个虚拟的世界，让佩戴者产生沉浸感，如下图所示：

上面中屏幕中的虚拟世界画面，是由 OpenGL 渲染的 3D 世界。我们这里不讨论分屏、反畸变原理，所以只看其中的一边屏幕。我们先说下 OpenGL 中构建虚拟世界的 MVP 矩阵：
MVP 矩阵
假设 3D 空间中有一">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/apple_icon.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/apple_icon.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">

</head>

  <body>
    <header>
      <div>
		
		<div id="header_author">
		</div>
		

         <!--
         
           <div id="imglogo">
           <a href="/"><img src="/img/logo.svg" alt="Light.Moon" title="Light.Moon"/></a>
           </div>
         
         -->

			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Light.Moon">Light.Moon</a></h1>
				<h2 class="blog-motto">三月学长的小站</h2>
			</div>

			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">首页</a></li>
					
						<li><a href="/1986/12/20/文章索引">索引</a></li>
					
						<li><a href="/archives">归档</a></li>
					
					<li>
					

                      <form class="search" action=http://search.light3moon.com/cse/search target="_blank">
                      <label>搜索</label>
                      <!--
                      <input name="s" type="hidden" value="undefined">
                      -->
                      <input name="s" type="hidden" value="12628367885198549364">
                      <input type="text" name="q" size="30" placeholder="搜索"> <br>

                      
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/17/VR HeadTracking 分析/" title="VR HeadTracking 分析" itemprop="url">VR HeadTracking 分析</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://www.light3moon.com" title="Mingming">Mingming</a>
    </p>
  <p class="article-time">
    <time datetime="2018-01-17T10:18:16.000Z" itemprop="datePublished">2018 1月 17</time>
    更新日期:<time datetime="2020-02-07T10:18:16.000Z" itemprop="dateModified">2020 2月 7</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#基本原理"><span class="toc-number">1.</span> <span class="toc-text">基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MVP_矩阵"><span class="toc-number">1.1.</span> <span class="toc-text">MVP 矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#头部跟踪"><span class="toc-number">1.2.</span> <span class="toc-text">头部跟踪</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据通路"><span class="toc-number">2.</span> <span class="toc-text">数据通路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#底层原始数据"><span class="toc-number">2.1.</span> <span class="toc-text">底层原始数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#头部跟踪模块数据融合"><span class="toc-number">2.2.</span> <span class="toc-text">头部跟踪模块数据融合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用渲染线程获取朝向"><span class="toc-number">2.3.</span> <span class="toc-text">应用渲染线程获取朝向</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#打包处理"><span class="toc-number">3.</span> <span class="toc-text">打包处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tile_Correct"><span class="toc-number">4.</span> <span class="toc-text">Tile Correct</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校正原理"><span class="toc-number">4.1.</span> <span class="toc-text">校正原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#细节处理"><span class="toc-number">4.2.</span> <span class="toc-text">细节处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Yaw_Correct"><span class="toc-number">5.</span> <span class="toc-text">Yaw Correct</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校正原理-1"><span class="toc-number">5.1.</span> <span class="toc-text">校正原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#细节处理-1"><span class="toc-number">5.2.</span> <span class="toc-text">细节处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#朝向预测"><span class="toc-number">6.</span> <span class="toc-text">朝向预测</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Sensor_hub_gyro_偏移校准"><span class="toc-number">7.</span> <span class="toc-text">Sensor hub gyro 偏移校准</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校准流程"><span class="toc-number">7.1.</span> <span class="toc-text">校准流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#静置检测流程"><span class="toc-number">7.2.</span> <span class="toc-text">静置检测流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参数配置"><span class="toc-number">7.3.</span> <span class="toc-text">参数配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考资料"><span class="toc-number">8.</span> <span class="toc-text">参考资料</span></a></li></ol>
		</div>
		
		<h1 id="基本原理">基本原理</h1>
<p>VR 通过分屏渲染一个虚拟的世界，让佩戴者产生沉浸感，如下图所示：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/vr_theory_1.png" alt="插图"><br><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/vr_theory_2.png" alt="插图"></p>
<p>上面中屏幕中的虚拟世界画面，是由 OpenGL 渲染的 3D 世界。我们这里不讨论分屏、反畸变原理，所以只看其中的一边屏幕。我们先说下 OpenGL 中构建虚拟世界的 MVP 矩阵：</p>
<h2 id="MVP_矩阵">MVP 矩阵</h2>
<p>假设 3D 空间中有一个物体，如下图所示：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_1.png" alt="插图"></p>
<p>假设 (0,0,0,) 为物体的中心，那么这个物体的其他顶点都相对这个中心有自己的坐标。3D 空间也有自己的坐标，这个叫做世界坐标。如果要把这个物体放到 3D 空间中（在3D空间显示，也就是在虚拟世界显示），那么需要将物体的坐标转化为世界坐标。进行这个运算的矩阵叫做<strong>模型矩阵（Model Matrix）</strong>：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_2.png" alt="插图"><br><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_3.png" alt="插图"></p>
<p>在虚拟世界中创建了物体，作为人（用户），需要能够感知（看到）这个世界（中的物体），假设有台摄像机在记录这个虚拟世界，那么这个摄像机以不同的角度就能观察到虚拟世界中的不同内容，也就是存在某种转化，把虚拟世界中的内容转化到摄像机当中（虚拟世界坐标转化到摄像机坐标）。进行这个运算的叫<strong>视图矩阵（View Matrix）</strong>：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_4.png" alt="插图"><br><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_5.png" alt="插图"></p>
<p>但是最后虚拟世界需要显示到一个2D的屏幕上，所以需要将摄像机中看到的内容投影到一个2D的平面上（摄像机摄影了，放映到屏幕上）。一般的这个投影是个锥形的（OpenGL 的一种投影，叫<strong>透视投影 Perspective</strong>）。进行这个投影运行的叫<strong>投影矩阵（Project Matrix）</strong>：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_6.png" alt="插图"><br><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_7.png" alt="插图"></p>
<p>经过上面的一些列变化（矩阵运算），最终就能将一个3D的虚拟世界显示到一个2D的屏幕上，上面的矩阵运算一般通过矩阵的乘法，在一起运算，所以上面的三个矩阵，在 OpenGL 中就合在一起叫 <strong>MVP 矩阵</strong>。</p>
<p>举个形象点的例子：蓝色的是虚拟世界中的物理，红色的表示摄像机透视投影的锥形：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_8.png" alt="插图"></p>
<p>那么投到一个矩形的屏幕上虚拟世界中的物体就会变形成这样：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_9.png" alt="插图"></p>
<p>然后显示到2D窗口中最终图像是就是这样的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/mvp_10.png" alt="插图"></p>
<h2 id="头部跟踪">头部跟踪</h2>
<p>那么头部跟踪和前面介绍的 MVP 矩阵有什么关系呢。其实人戴着 VR 头盔转动，就是想和一个摄像机一样观察看虚拟世界不同的场景，所以<strong>头部跟踪就是将 VR 头盔的转动</strong>，反映到 View Matrix 上。那怎么反映，这里再来介绍一下另外一个概念：在3D空间中如何转动一个物体。</p>
<p>3D 空间有3个轴x，y，z，在 VR 领域大家更习惯用 <strong>yaw（y），pitch（x），roll（z）</strong>来表示。如果依次沿着x，y，z轴转动相应的角度，那么这个物体就有得到一个新的朝向（<strong>Orientation</strong>）：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/euler_angle.png" alt="插图"></p>
<p>沿着这3个轴转动的角度叫做 <strong>欧拉角（Euler Angle）</strong>。欧拉角是有顺序的，按照不同的顺序变化，角度是不同的：例如 x，y，z 和 y，x，z 。我们的 sdk 使用的顺序是 y，x，z，也就是 yaw，pitch，roll。</p>
<p>欧拉角可以表示一个朝向，但是欧拉角是三个独立的角度，不利于连续的插值变化运算，所以有人发明了<strong>四元数（Quaternion）</strong>。欧拉角和四元数可以相互转化，具体的数学公式这里不详细说了（可以网上查资料），sdk 里有 api 可以直接使用。</p>
<p>利用欧拉角可以在3D空间中进行旋转操作，也就是说摄像机的转动可以使用欧拉角来运算。头部跟踪就是要得到 VR 头盔实时转动的欧拉角，然后通过 MVP 反映到渲染的图像上。</p>
<p>在 android 平台上，陀螺仪（Gyroscope）上报的3轴的数据正好就是表示3个轴旋转的角速度：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/android_gyro.png" alt="插图"></p>
<p>假设使用一个四元数来表示当前摄像机（头盔）的朝向（O）。那么在 t0 时刻 O 初始值为 0。经过 delta 时间，在 t1 时间读取陀螺仪的角速度 s，那么这个时刻，头盔转动过的欧拉角是：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;angle = delta * s</p>
<p>那么在当前朝向的基础上转动这个欧拉角，就能得到头盔的新朝向 O1：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;O1 = O + angle</p>
<p>如果持续重复这个过程，那么摄像机（头盔）就能模拟人转动想看到的虚拟世界中的场景，这个过程就叫<strong>头部跟踪（HeadTracking）</strong>。</p>
<h1 id="数据通路">数据通路</h1>
<p>全志的 sdk 中头部跟踪的数据通路是这样的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/data_flow.png" alt="插图"></p>
<p>上面的数据通路主要分成3块：</p>
<h2 id="底层原始数据">底层原始数据</h2>
<p>应用通过 API 让 android system service 中的 sensor service 打开 sensor hub，sensor hub 就开始以指定的频率上报需要的数据，VR 的头部跟踪目前主流用到的是3个传感器的数据：陀螺仪（<strong>gyro</strong>）、重力加速度（<strong>accel</strong>），地磁（<strong>mag</strong>），每一个传感器有 x、y、z 3个轴的数据，将这3个传感器的数据融合（fusion）得到一个四元数的朝向，就叫9轴融合。市面上很多VR说的支持9轴传感器，就是融合陀螺仪、重力、地磁的意思。sensor service 读到数据后，就会通过 local socket 发送给上层应用。</p>
<h2 id="头部跟踪模块数据融合">头部跟踪模块数据融合</h2>
<p>头部跟踪模块在软件分层中属于应用层，头部跟踪会开启一个后台采样线程将收到的 gyro、accel、mag 重复的按照下面步骤融合（fusion）成四元数（Quat）朝向（Orientation）：</p>
<ol>
<li>将 gyro、accel、mag 打包成一个数据包，具体后面说明。</li>
<li>gyro 通过累积变化，计算当前朝向（第一章说明）。</li>
<li>重力校准（tilt correct），具体后面说明。</li>
<li>地磁校准（yaw correct），具体后面说明。</li>
<li>保存最后计算的朝向，等待渲染线程来取。</li>
</ol>
<h2 id="应用渲染线程获取朝向">应用渲染线程获取朝向</h2>
<p>一般的 VR OpenGL 应用都会有一个渲染线程，会在每一帧从头部跟踪模块获取到最新的朝向，从朝向中获取转动欧拉角，然后应用到视图矩阵。</p>
<p>这里的渲染线程和上面的采样线程是独立的，采样线程只是不停的融合 sensor 数据，实时更新最新朝向，等待有人来取。一般来说在 VR 上 gyro、accel 的采样率都是 1000Hz 以上（我们的目前是 800Hz），而且渲染的帧率一般是 60fps（某些高端的 VR 已经到 70fps 甚至 120fps 了）。这里就有一个疑问，既然渲染的帧率才 60，那为什么采样率需要那么高呢？这是因为采样率越高，那个计算出来的最新朝向就越能代表当前设备真实的朝向，表现在画面上的延迟感就会更低。这也就是为什么 VR 上要单独设计一个 sensor hub 的原因（高采样率的 sensor 如果通过通用 cpu 来处理，那么会对上层系统造成极大的负载，所以使用一个小 cpu 来单独处理高采样率的 sensor）。</p>
<p>所以我们 sdk 里的数据模型是：采样线程在后台以高频率接收 sensor 数据，并融合出最新的朝向，保存起来。前台的渲染线程按照自己的帧率从采样线程获取朝向。</p>
<p>简洁的来说整个数据通路各个模块的输入输出就是下面这个样子：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/data_flow_in_out.png" alt="插图"></p>
<h1 id="打包处理">打包处理</h1>
<p>接下来我们细分几块来把之前数据通路的几个地方说清楚。首选是打包处理。在头部跟踪模块接收到 sensor service 发送过来的 sensor 数据，会有一个打包的操作。这个包简单来说包含5个数据：</p>
<ol>
<li>Gyro：陀螺仪，当前转动角速度，用于计算朝向增量变化</li>
<li>Accel：重力加速度，当前的位置信息，用于 tile correct</li>
<li>Mag：地磁，当前的位置信息，用于 yaw correct</li>
<li>Delta：sensor 上报的时间间隔，当前的时间戳与上一个数据包的时间戳相减得到，<strong>朝向增量变化使用这个 dt</strong>，这个是 sensor hub 带上来的时间</li>
<li>TimeStamp：收到 sensor 的时间戳，<strong>预测朝向计算使用这个 dt</strong>，这个是上层系统的时间</li>
</ol>
<p>上面5个数据组成一个数据包（结构体 sdk 里叫 SFBodyMessageFrame）。这里先说一下，为什么需要打包。由于 sensor 的零漂误差（drift error），所以需要 tile correct 和 yaw correct（后面在说）。所以理论上来说需要 gyro、accel、mag 这3个数据一一对应（要拿当前时刻的 accel 和 mag 来校准当前时刻的 gyro 转动）。</p>
<p>但是这是理论情况，实际上，很有可能底层上报的数据并不是严格一一对应的（底层可以一次上报同时包括 gyro、accel、mag 三个数据的）。目前我们的平台，首先 gyro、accel 的采样率是 800Hz，mag 是 100Hz，gyro、accel 和 mag 就不可能一一对应上。然后 gyro、accel 虽然频率一样，但是上报也不是成对的，经常是先报一个 gyro，然后再 accel，或者反过来。</p>
<p>所以 headtracking 这边的前处理就是：</p>
<ol>
<li>创建3个 fifo 分别保存收到的 gyro、accel、mag</li>
<li>以 gyro fifo 中的数量为准（cnt 个），循环 cnt 次，分别从3个 fifo 中把 gyro，accel，mag 取出，打包到结构体中（SFBody）；将已取出打包的数据分别从 fifo 中删除。</li>
<li>保存上一次打包的 gyro 的 timestamp（sensor hub 带上来的，lastGyroTimestamp），将当前的 gyro 的 timestampe 和 lastGyroTimestamp 相减得到 Delta。并且获取当前系统时间戳，作为 SFBody 的 Timestamp（AbsoluteTimeInSeconds）。</li>
<li>如果2中 gyro fifo 为空，那么等待 gyro 数据。在等待过程中，如果 accel fifo 中的数据超过了一定时间没有被打包走，那么认为是过时的数据，将过时的 accel fifo 清空。</li>
</ol>
<p>用图来表示，大概是这样的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/data_pack.png" alt="插图"></p>
<p>解释一下上面的打包处理：</p>
<p>对于2，打包的 SFBody 中<strong>可以没有 accel 或者 mag，但是一定会有 gyro</strong>。这是因为就算朝向变化，是依靠 gyro 来计算的，如果这次的数据没有 gyro，那么就无法计算朝向变化，accel 和 mag 只是用来校准的而已，没有只是影响朝向的精度。这样处理，是尽可能的让 gyro 和 accel 一一对应，同时放宽条件，允许底层上报数据的时候存在一定的偏差，不严格一一对应。</p>
<p>对于3，这里用到了2套时间系，分别是 sensor hub 上报 sensor 带上来的时间戳，和上层系统（android）的系统时间戳。前者是用来计算朝向变化的（angle x dt）。后者是用来计算预测的，预测后面再说。为什么使用2套时间系，是因为 sensor hub 带上来的时间戳，是 sensor 采样时候的时间戳，表示2个 sensor 时间之间的时间间隔，而如果 android 系统的时间戳，表示的是 headtracking 收到 sensor service 发送 sensor 的时间。这2套时间体系是有误差的，所以在计算 deltaT 的时候只能统一采用一套。所以<strong>计算朝向变化统一使用 sensor hub 上报的时间戳</strong>。预测需要应用传入时间戳，而应用只能获取到 android 系统的时间，所以<strong>预测统一使用 android 系统的时间系统</strong>。</p>
<p>对于4，由于2没有严格要求 gyro 和 accel 一一对应。所以这次采用一个过时机制，保证打包的 gyro、accel 在时间上相差不是特别大。而mag fifo 不处理，因为 mag 的采样率比 gyro、accel 低很多，而且在 yaw correct 的时候会处理 mag 采样率的延迟，所以不需要在打包的时候去考虑 mag 的过时。</p>
<h1 id="Tile_Correct">Tile Correct</h1>
<p>说校准之前先接着补充说一下第一章的基本原理。第一章说了 headtracking 就是让 sensor 数据表现在摄像机上，这里说一下怎么旋转摄像机的。VR 世界里面，需要构造一个虚拟世界，那么世界肯定要是正的，例如说这样的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/vr_theory_2.png" alt="插图"></p>
<p>OpenGL 的初始状态世界坐标是正的，假设 VR 设备这个时候也是正的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/tile_correct_1.png" alt="插图"></p>
<p>如果 VR 设备向右边歪一下，屏幕也就往右边歪了，那么世界坐标就歪了：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/tile_correct_2.png" alt="插图"></p>
<p>往如果要继续保持世界坐标系看起来是正的，这个时候摄像机就需要向反方向旋转：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/tile_correct_3.png" alt="插图"></p>
<p>头部跟踪的本质就是<strong>通过旋转视图矩阵（摄像机），让世界坐标系看上去是正的</strong>。这里就有一个概念：VR 世界里面，看上去的世界坐标是正的（下面为了方便，就直接说世界坐标了，而不特意强调是看上去的世界坐标）。</p>
<h2 id="校正原理">校正原理</h2>
<p>说明白了上面的概念后，就可以来说 tile correct 了。为什么需要 tile correct，是因为 gyro 在实际的采样过程中是会存在误差的，可能每一次的误差并不是很大（sensor 厂商的 datasheet 范围内），但是由于持续的使用，就会存在累积误差，一段时间后，累积误差就会很大，从而能让使用者感知到位移误差。gyro 是有3个轴的，所以误差是在3个轴都有的，这里说的 tile correct 指的是倾斜误差，指的是 x，z 轴的误差，为什么没 y 轴的，后面会说明。</p>
<p>由于 gyro 的累积误差导致 x，z 轴旋转有误差，所以旋转的摄像机看到的世界坐标就是倾斜的，所以叫 tile correct。那怎样校正呢。</p>
<ol>
<li>我们假设有一个竖直向上的向量 up (0, 1, 0)</li>
<li>那么有 up’ = up * current orientation， up’  就是 up 在当前朝向上的分量</li>
<li>如果 gyro 没有误差，那么计算出来的 orientation 应该要使摄像机看到的世界坐标也是正的，那么 up’ 应该还是 (0, 1, 0)</li>
<li>也就是说如果 up’ 和 up 存在夹角（error），那么这个夹角就是误差角，我们只要将当前朝向回正这个误差角，就做到校正了（保证世界坐标系是正的）</li>
<li>我们知道地球的重力加速度是永远垂直向下的，在 android 上上报的方向正好相反，向上是正的，所以我们可以用 accel 来测量（<strong>measured</strong>） up’。用当前朝向和 accel 可以计算出 up’ ，然后用 up’  和理论 up(0, 1, 0)计算夹角，就能得到误差偏移角（error）。</li>
</ol>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/tile_correct_4.png" alt="插图"><br><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/tile_correct_5.png" alt="插图"></p>
<p>上面这个过程就是我们的 headtracking 中使用的 tile correct 的原理。因为为沿 y 轴旋转 accel 是没有变化的，<strong>所以 tile correct 只能校正 x，z 轴</strong>。</p>
<h2 id="细节处理">细节处理</h2>
<p>下面说一下 tile correct 的几点细节：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;1. 由于 accel 也是存在误差的（只要是 sensor 都会存在误差），但是 accel 的变化没有 gyro 那么明显，所以 headtracking 中使用了一定的过滤方法来过滤一定样本的 accel。具体的过滤方法可以去看代码（大致是一定样本数量+低斯滤波）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;2. tile correct 的 error 角度，如果太大的话，那么用户是会有明显的感知的。为了避免这个问题，有下面的处理：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a. 第一次 tile correct （GetSize() == 1）允许完全使用 error 角度计算。 因为第一次 tile correct 一般都是刚开机，或者是休眠唤醒的时候。这个时候的设备的朝向一般都不是正的，坐标系是默认按照屏幕方向的，所以这个时候进行完全校准，能让坐标系回到正方向。但是相对的，如果这个过程被用户看到了，就会发现画面突然跳变了一下。这里就引申出一个问题，休眠唤醒的时候画面会跳一下。其中这个 tile correct 是一点原因（我们 VR9 上的这个跳动问题不止这一个原因，还有显示相关的）。处理方法就是，可以尽量提高头部跟踪的启动速度，和第一次 tile correct 的速度，如果赶在渲染第一帧之前就完成第一次 tile correct 那么画面就不会有“明显”的跳动感。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b. 如果 error 角度不大(Abs(error.w) &lt; cos(snapThreshold / 2))，并且设备“相对静置”(Confidence &gt; 0.75)，那么也允许完全使用 error角度。相对静置，其实就是上面的 accel 的过滤采样的样本的方差，通过一个公式计算得到一个信任分数（Confidence，和sensorhub gyro 那章判断静置的分数计算类似）。如果设备非水平转动，那么 accel 的3轴数值会变化（水平转动，accel 的变化不大），那么这个分数就会比较低。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c. 设备“比较静置”(Confidence &gt; 0.5)，那么对计算出的 error 角度进行一个插值（Nlerp），弱化补偿效果，让补偿转动不明显。比较静置就是上面那个信任分数稍微低一点。插值的实现自己去看代码吧，我也不是熟，反正就是弱化这个角度的作用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d. 如果不静置，就不进行 tile correct。也就是上面的信任分数很低。</p>
<p>上面的处理情况，代码就是这样的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">Quatf correction;</div><div class="line"><span class="keyword">if</span> (FAccelHeadset.GetSize() == <span class="number">1</span> ||</div><div class="line">    ((Alg::Abs(error.w) &lt; <span class="built_in">cos</span>(snapThreshold / <span class="number">2</span>) </div><div class="line">    && FAccelHeadset.Confidence() &gt; <span class="number">0.75</span>)))</div><div class="line">{</div><div class="line">    <span class="comment">// full correction for start-up</span></div><div class="line">    <span class="comment">// or large error with high confidence</span></div><div class="line">    correction = error;</div><div class="line">}</div><div class="line"><span class="keyword">else</span> <span class="keyword">if</span> (FAccelHeadset.Confidence() &gt; <span class="number">0.5</span>)</div><div class="line">{</div><div class="line">    correction = error.Nlerp(Quatf(), gain * deltaT);</div><div class="line">}</div><div class="line"><span class="keyword">else</span></div><div class="line">{</div><div class="line">    <span class="keyword">return</span>;</div><div class="line">}</div><div class="line"></div></pre></td></tr></table></figure>

<h1 id="Yaw_Correct">Yaw Correct</h1>
<h2 id="校正原理-1">校正原理</h2>
<p>上面 accel 只能校正 x，z 轴，那么下面就是要进行 y 轴校正了（yaw correct）。和 tile correct 的原理类似，对于水平方向上来说，如果存在一个水平指北的向量，并且我们可以 measured 这个方向，那么我们可以用和 tile correct 类似的原理那校正 y 轴。</p>
<p>我们很自然的想到地磁（mag），可以用做指南针（其实它是指北的）。但是和 accel 不同的是，地磁在不同的区域是不一样的：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/yaw_correct_1.png" alt="插图"></p>
<p>如果地磁与水平面的夹角（inclination angle）过大，那么它投影到水平面上的分量就很小。可以看到芬兰附近的 inclination angle 是很大的。还有就是其实地磁也不是完美的指向北方，某些地方是也是存在偏差角度的（declination angle）。另外外界对地磁测量也存在影响，例如硬铁（hard iron）和软铁（soft iron）（具体的网上查资料吧，我也不是特别清楚）。</p>
<p>所以不像 accel 可以直接使用，用来作为标准来校正。那么其实有一种方法可以规避掉地磁不准的情况：就是不使用地磁的数值来校正，而且是用它作为一个参照。因为我们的目的，并不是指北，而是为了校正 y 轴旋转。</p>
<p>方法就是：</p>
<ol>
<li>选取一个时刻（t1）的朝向（Orientation）O 和地磁（mag） ，计算出世界坐标下的地磁向量 m，作为参考（Ref）。</li>
<li>经过 dt 时间后，t2 时刻的朝向 O’ 和 地磁计算出此时世界坐标下的地磁向量 m’。</li>
<li>理论上如果没有 y 轴旋转偏差，那么 m’ 和 m 应该是重合的。所以 m’ 和 m 的夹角就是偏差角（yawError）。</li>
<li>经过一段时间后，检测作为 Ref 的 O 和当前 O’ 的夹角（偏差），如果大于某个阀值，那么用 O’ 和 m’ 作为新的 Ref。 </li>
</ol>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/yaw_correct_2.png" alt="插图"></p>
<h2 id="细节处理-1">细节处理</h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;1. 前面原理里用某个时刻的 Orientation 和 mag 作为 Ref。Orientation 是 gyro 计算出来的。但是 gyro 的采样率比 mag 要高很多（我们平台上 gyro 是 800MHz，mag 是 100MHz）。所以 Orientation 和 mag 无法直接一一对应上的。因此使用了一个 buffer 缓冲区来保存一定数量的 Orientation，当前时候的 mag 要获取 Orientation 的时候，根据一个回退算法获取前一个时刻的 Orientation（因为 mag 的采样率比 gyro 低，所以要往前找）：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span></div><div class="line">{</div><div class="line">    MagMaxReferences = <span class="number">1000</span>,</div><div class="line">    MagLatencyBufferSizeMax = <span class="number">512</span>,</div><div class="line">    MagLatencyCompensationMilliseconds = <span class="number">95</span>,</div><div class="line">};</div><div class="line"></div><div class="line"><span class="comment">// Determine how far to look back in buffer.</span></div><div class="line"><span class="keyword">int</span> backDist = (<span class="keyword">int</span>) ((<span class="keyword">float</span>) MagLatencyCompensationMilliseconds / (<span class="number">1000.0f</span> * deltaT));</div><div class="line"></div></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;2. 刚开始 yaw correct 的时候（头部跟踪模块初始化，或是休眠唤醒的时候），会等待一段时间（现在目前是 5s），等待 tile correct 将位置回正再开始 yaw correct。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;3. 如果当前的 Orientation 对应的 gyro 转动速度太快（有一个阀值），那么就不做 yaw correct，因为转动过快，yaw correct 已经没意义了（tile correct 也是一样的，运动中不校正）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;4. 如果当前的地磁，投影到水平面的分量太小，则不校正：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Verify that the horizontal component is sufficient.</span></div><div class="line"><span class="keyword">if</span> (magInWorldFrame.x * magInWorldFrame.x + magInWorldFrame.z * magInWorldFrame.z &lt; minMagLengthSq)</div><div class="line">{</div><div class="line">    <span class="keyword">return</span>;</div><div class="line">}</div><div class="line"></div></pre></td></tr></table></figure>

<p>剩下还有一些其它小细节，例如说 Ref 的一些分数取值，看下代码理解一下了。</p>
<h1 id="朝向预测">朝向预测</h1>
<p>朝向预测其实比较简单，原理就是通过上面的 fusion 算法，得到最后的朝向（Orientation）和转动角速度（AngularVelocity），然后给定预测的时间（pdt），在当前朝向的基础上加上 AngularVelocity * pdt 就是预测朝向了：</p>
<pre>
pose.Orientation = pose.Orientation * Quatf(angularVelocity, angularSpeed * dynamicDt)
</pre>

<p>预测算法的用途可以参看 ATW 的时序说明，简单来说就是应用渲染好的画面，送去显示，需要一段时间，如果按照实时朝向去渲染画面，那么最终在屏幕上看到的画面其实是之前一段时间的，就存在的延迟感。所以适当的预测，然后让应用使用未来的朝向来渲染，来补偿送显的延迟。</p>
<p>预测算法主要还是预测时间的选择上，例如说 ATW 选择的是 1.5 个 VSync。但是除了参数的自主选择，内部算法为了稳定性，还是做了一定的限制：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">const</span> <span class="keyword">float</span> linearCoef   = <span class="number">1.0</span>;</div><div class="line">Vector3f angularVelocity = poseState.AngularVelocity;</div><div class="line"><span class="keyword">float</span> angularSpeed       = angularVelocity.Length();</div><div class="line"></div><div class="line"><span class="comment">// This could be tuned so that linear and angular are combined with different coefficients</span></div><div class="line"><span class="keyword">float</span> speed = angularSpeed + linearCoef * poseState.LinearVelocity.Length();</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">float</span> slope = <span class="number">0.2</span>; <span class="comment">// The rate at which the dynamic prediction interval varies</span></div><div class="line"><span class="keyword">float</span> candidateDt = slope * speed; <span class="comment">// TODO: Replace with smoothstep function</span></div><div class="line"></div><div class="line"><span class="keyword">float</span> dynamicDt         = predictionDt;</div><div class="line"></div><div class="line"><span class="comment">// Choose the candidate if it is shorter, to improve stability</span></div><div class="line"><span class="comment">// predictionDt &lt; 0 meaning fatal error occured, never use it</span></div><div class="line"><span class="keyword">if</span> (predictionDt &gt;= <span class="number">0</span> && candidateDt &lt; predictionDt) {</div><div class="line">    dynamicDt = candidateDt;</div><div class="line">}</div><div class="line"></div></pre></td></tr></table></figure>

<p>限制了预测的时间范围（不允许过大），根据当前速度和加速进行限制。不过我们现在加速度没有计算，所以限制只和速度有关。</p>
<h1 id="Sensor_hub_gyro_偏移校准">Sensor hub gyro 偏移校准</h1>
<p>一般来说如果把设备静止放置，理想情况下，gyro 上报的数据应该是 0，但是真实的情况是会存在误差的。一般来说在某些外界因素下，底层采集的原始数据有可能存在一定情况的偏移，例如说下面这种情况（静置情况下）：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/sensorhub_draft.png" alt="插图"></p>
<p>可以看到 gyro 底层采集到的数据很明显的偏移了一个数值（均值大概 0.02 rad/s 转化为角度大概是 1.14 deg/s），偏移很明显，这种情况下，头部跟踪融合出来的朝向数据，是会慢慢的超一个方向转动的。前面的 tile correct 和 yaw correct 均无法消除这种级别的偏差。</p>
<p>这种情况下，就需要底层采样上报的时候进行偏移校准。虽然这部分不属于上次头部跟踪，但是会影响到最后头部跟踪的最终效果，所以这里也调试分析了一下。google 提供的 contexthub（sensorhub）自带了一个动态的校准算法。</p>
<p>从上面的图可以看出来，其实校准的核心在于补偿静置时候的偏移误差。 就是计算出静置时候的 gyro 的数值（理论上来说这个时候 gyro 的值应该是0），然后在上报的时候减去这个补偿值就可以了。</p>
<h2 id="校准流程">校准流程</h2>
<p>google contexthub gyro 动态校准流程是：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/sensorhub_correct_1.png" alt="插图"></p>
<p>大概流程是：</p>
<ol>
<li>采集 gyro, accel, mag</li>
<li>每次更新 gyro, accel, mag 到静置检测器（stillness detect），判断当前是否处于静置状态</li>
<li>如果处于静置状态并且维持一段时间，那么就将这段时间内 gyro 的平均值作为校准补偿值。</li>
</ol>
<p>上述流程是一直在都在运行，也就是说在不停的检测是否处于静置状态，如果处于静置状态一段时间，那么就更新校准补偿值。从上面的流程图可以看到，处于静置状态持续的时间有2个阀值判断，一个是 min_stillness_duration，一个是 max_stillness_duration。这个2个值的区别是：</p>
<p><strong>min_stillness_duration:</strong><br>之前处于静置状态，当前不处于静置状态了，那么从开始处于静置状态的时间开始算，到当前不处于静置状态，如果这段时间大于 min_stillness_duration ，那么触发更新校准补偿值操作。</p>
<p><strong>max_stillness_duration:</strong><br>之前处于静置状态，现在也是静置状态（一直处于静置状态），那么从开始处于静置状态时间开始，到当前的时间，大于 max_stillness_duration，那么触发更新校准补偿值操作。</p>
<p>每次更新校准值后，都会重置静置状态检测器的状态，然后重新判断。当第一次进入静置状态（通过判断 prev_still 这个 flag）的时候会记录开始静置的时间戳。</p>
<p>min_stillness_duration、max_stillness_duration 这2个值都是可以配置，我们 VR9 平台根据调试，选择的是 3s 和 4s。</p>
<h2 id="静置检测流程">静置检测流程</h2>
<p>接下来看一下，这个算法里面，关于静置检测的算法（上面流程中的 stillness detect）。静置检测的算法流程大致如下：</p>
<p><img src="https://mingming-killer.github.io/img/pics/android/vr-headtracking/sensorhub_correct_2.png" alt="插图"></p>
<p>检测流程为：</p>
<ol>
<li>采集 gyro、accel、mag</li>
<li>更新 gyro、accle、mag 数据，确定一个窗口时间和超时时间（一段采样时间）</li>
<li>在这个窗口时间（window_time_duration）内（不超时），对采样的数据计算方差（还可以计算平均值，用作后面的校准值）</li>
<li>通过方差计算得到一个可信度得分（confidence），如果得分高于设定的阀值，那么认为是静置的</li>
</ol>
<p>首先是采样窗口的确定。window_time_duration 这个值也是可以配置的，VR9 上配置的是 1.5s。当检测器状态被重置，会拿第一个采样到的数据的时间戳当做窗口开始时间（window_start_time），然后 window_start_time + window_time_duration 就是 window_end_time。超时是 2* window_time_duration。超时是什么意思呢？这里的静置检测使用到了 gyro、accel、mag 3个 sensor 的数据来判断。开始的时间是第一个采集到 gyro 的时间，如果这段时间内 accel、mag 一直没采集到数据（num_acc_samples &lt; 1），那么就认为是超时，重置状态，重新开始一个新采样窗口。</p>
<p>上面提到了最后是通过一个分数来判断的。这个分数是通过方差计算出来的。这里方差公式不贴了，网上很多，有比较简单（平均值也是），贴一下分数的计算公式：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;1.设定一个方差的阀值，var_threshold，可以配置，VR9 配置为 0.00018 rad/s，还有一个方差的阀值变化范围值，threshold_delta，可以配置，VR9 配置为 0.00001 rad/s。根据这2个值可以得到2个范围上下限：</p>
<p>lower_var_thresh = var_threshold - threshold_delta<br>upper_var_thresh = var_threshold + threshold_delta</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;2. 如果当前窗口的3轴方差（win_var_x, win_var_y, win_var_z）其中有一个轴高于 upper_var_thresh 那么 confidence 为 0。方差越小，代表变化越小，也就越说明静置不动，confidence 的取值为 [0, 1]，越接近1得分越高，就越代表可信（静置不动）。如果3轴方差全部小于 lower_var_thresh 则 confidence 为 1.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;3.如果不是上面2种情况，那么按照下面的公式来计算 confidence: </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Compute the stillness confidence score.</span></div><div class="line"><span class="comment">// Each axis score is limited [0,1].</span></div><div class="line">tmp_denom = <span class="number">1.f</span> / (upper_var_thresh - lower_var_thresh);</div><div class="line">gyro_still_det-&gt;stillness_confidence =</div><div class="line">    gyroStillDetLimit(</div><div class="line">        <span class="number">0.5</span> - (gyro_still_det-&gt;win_var_x - var_thresh) * tmp_denom) *</div><div class="line">    gyroStillDetLimit(</div><div class="line">        <span class="number">0.5</span> - (gyro_still_det-&gt;win_var_y - var_thresh) * tmp_denom) *</div><div class="line">    gyroStillDetLimit(</div><div class="line">        <span class="number">0.5</span> - (gyro_still_det-&gt;win_var_z - var_thresh) * tmp_denom);</div><div class="line"></div></pre></td></tr></table></figure>

<p>上面的 gyroStillDetLimit 的作用就是限制输入参数的范围为 0 ~ 1.0f，即 &lt; 0 的为0，&gt; 1 的为 1.0f。</p>
<p>简单总结一下，上面的算法的核心就是通过一段时间的采样，然后计算方差（变化幅度），根据阀值来判断是否处于静置；处于静置，就使用这段时间的平均值作为新的补偿偏移（bias）；上报的数据减去这个偏移值完成校准。</p>
<h2 id="参数配置">参数配置</h2>
<p>这里一共有好几个参数可以配置：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> gyroCalInit(<span class="keyword">struct</span> gyroCal_t* gyro_cal, uint64_t min_still_duration,</div><div class="line">             uint64_t max_still_duration,</div><div class="line">             <span class="keyword">float</span> bias_x, <span class="keyword">float</span> bias_y, <span class="keyword">float</span> bias_z,</div><div class="line">             uint64_t calibration_time,</div><div class="line">             uint64_t window_time_duration,</div><div class="line">             <span class="keyword">float</span> gyro_var_threshold,</div><div class="line">             <span class="keyword">float</span> gyro_confidence_delta,</div><div class="line">             <span class="keyword">float</span> accel_var_threshold,</div><div class="line">             <span class="keyword">float</span> accel_confidence_delta,</div><div class="line">             <span class="keyword">float</span> mag_var_threshold,</div><div class="line">             <span class="keyword">float</span> mag_confidence_delta,</div><div class="line">             <span class="keyword">float</span> stillness_threshold,</div><div class="line">             <span class="keyword">int</span> remove_bias_enable) </div><div class="line"></div><div class="line">gyroCalInit(&mTask.gyro_cal,</div><div class="line">      <span class="number">3e9</span>,     <span class="comment">// min stillness period = 3 seconds</span></div><div class="line">      <span class="number">4e9</span>,     <span class="comment">// max stillness period = 4 seconds</span></div><div class="line">      <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,   <span class="comment">// initial bias offset calibration</span></div><div class="line">      <span class="number">0</span>,       <span class="comment">// time stamp of initial bias calibration</span></div><div class="line">      <span class="number">1.5e9</span>,    <span class="comment">// analysis window length = 1.5 seconds</span></div><div class="line">      <span class="number">18e-5</span>f,   <span class="comment">// gyroscope variance threshold [rad/sec]^2 (0.00018)</span></div><div class="line">      <span class="number">1e-5</span>f,    <span class="comment">// gyroscope confidence delta [rad/sec]^2   (0.00001)</span></div><div class="line">      <span class="number">8e-3</span>f,    <span class="comment">// accelerometer variance threshold [m/sec^2]^2</span></div><div class="line">      <span class="number">1.6e-3</span>f,  <span class="comment">// accelerometer confidence delta [m/sec^2]^2</span></div><div class="line">      <span class="number">1.4f</span>,     <span class="comment">// magnetometer variance threshold [uT]^2</span></div><div class="line">      <span class="number">0.25</span>,     <span class="comment">// magnetometer confidence delta [uT]^2</span></div><div class="line">      <span class="number">0.88f</span>,    <span class="comment">// stillness threshold [0,1]</span></div><div class="line">      <span class="number">1</span>);       <span class="comment">// 1=gyro calibrations will be applied</span></div><div class="line"></div></pre></td></tr></table></figure>

<p>全志的 VR9 主要是调节了这几个参数： </p>
<p>min_stillness_duration, max_stillness_duration,<br>window_time_duration<br>gyro_var_threshold, gyro_confidence_delta<br>stillness_threshold</p>
<p>默认的参数，我们 VR9 gyro 静置的时候变化相对来说比较，原来默认的参数，在某些机器上经常无法判断静置的条件（静置情况下）。所以经常无法更新校准值，会导致缓慢的偏移。所以我们根据实际调试情况，适当的调整了阀值范围，让这套算法适应我们的 VR9。</p>
<p>google 的 contexthub 其实 accel，mag 也是有校准，不过由于并没有出什么问题，所以就没去研究。而且 google 的 contexthub 也带有 fusion 算法（其实就是 framework sensorservice 的 fusion 算法移过去了），以后也可以研究一下。</p>
<h1 id="参考资料">参考资料</h1>
<p>(1). HeadTrackingforOculusRift.pdf<br>(2). Vrbookbig.pdf: Tracking 章节<br>(3). <a href="http://www.opengl-tutorial.org/cn/beginners-tutorials/tutorial-3-matrices/" target="_blank" rel="external">有关 openGL 矩阵变化的原理</a><br>(4). headtracking source code: android/vendor/aw/public/packge/bin/headtracking<br>(5). context hub gyro calibrate source code: lichee/contexthub/firmware/src/algos</p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/vr/">vr</a><a href="/tags/opengl/">opengl</a>
  </div>


<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/VR/">VR</a>
</div>



<div class="article-share" id="share">

  <div data-url="http://www.light3moon.com/2018/01/17/VR HeadTracking 分析/" data-title="VR HeadTracking 分析 | Light.Moon" data-tsina="null" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2019/12/30/OpenGLES 入门学习/" title="OpenGLES 入门学习">
  <strong>上一篇:</strong><br/>
  <span>
  OpenGLES 入门学习</span>
</a>
</div>


<div class="next">
<a href="/2015/11/02/Android 应用内存泄漏分析/"  title="Android 应用内存泄漏问题分析">
 <strong>下一篇:</strong><br/> 
 <span>Android 应用内存泄漏问题分析
</span>
</a>
</div>

</nav>


	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#基本原理"><span class="toc-number">1.</span> <span class="toc-text">基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MVP_矩阵"><span class="toc-number">1.1.</span> <span class="toc-text">MVP 矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#头部跟踪"><span class="toc-number">1.2.</span> <span class="toc-text">头部跟踪</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据通路"><span class="toc-number">2.</span> <span class="toc-text">数据通路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#底层原始数据"><span class="toc-number">2.1.</span> <span class="toc-text">底层原始数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#头部跟踪模块数据融合"><span class="toc-number">2.2.</span> <span class="toc-text">头部跟踪模块数据融合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用渲染线程获取朝向"><span class="toc-number">2.3.</span> <span class="toc-text">应用渲染线程获取朝向</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#打包处理"><span class="toc-number">3.</span> <span class="toc-text">打包处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tile_Correct"><span class="toc-number">4.</span> <span class="toc-text">Tile Correct</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校正原理"><span class="toc-number">4.1.</span> <span class="toc-text">校正原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#细节处理"><span class="toc-number">4.2.</span> <span class="toc-text">细节处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Yaw_Correct"><span class="toc-number">5.</span> <span class="toc-text">Yaw Correct</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校正原理-1"><span class="toc-number">5.1.</span> <span class="toc-text">校正原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#细节处理-1"><span class="toc-number">5.2.</span> <span class="toc-text">细节处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#朝向预测"><span class="toc-number">6.</span> <span class="toc-text">朝向预测</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Sensor_hub_gyro_偏移校准"><span class="toc-number">7.</span> <span class="toc-text">Sensor hub gyro 偏移校准</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#校准流程"><span class="toc-number">7.1.</span> <span class="toc-text">校准流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#静置检测流程"><span class="toc-number">7.2.</span> <span class="toc-text">静置检测流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参数配置"><span class="toc-number">7.3.</span> <span class="toc-text">参数配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考资料"><span class="toc-number">8.</span> <span class="toc-text">参考资料</span></a></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
			<li><a href="/categories/Android-Development/" title="Android Development">Android Development<sup>32</sup></a></li>
		
			<li><a href="/categories/Android-Framework/" title="Android Framework">Android Framework<sup>49</sup></a></li>
		
			<li><a href="/categories/Basics-Knowledge/" title="Basics Knowledge">Basics Knowledge<sup>11</sup></a></li>
		
			<li><a href="/categories/Linux/" title="Linux">Linux<sup>24</sup></a></li>
		
			<li><a href="/categories/MiniGUI/" title="MiniGUI">MiniGUI<sup>12</sup></a></li>
		
			<li><a href="/categories/Other/" title="Other">Other<sup>9</sup></a></li>
		
			<li><a href="/categories/Performance/" title="Performance">Performance<sup>4</sup></a></li>
		
			<li><a href="/categories/VR/" title="VR">VR<sup>2</sup></a></li>
		
			<li><a href="/categories/Window/" title="Window">Window<sup>10</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			<li><a href="/tags/Linux/" title="Linux">Linux<sup>1</sup></a></li>
		
			<li><a href="/tags/android/" title="android">android<sup>85</sup></a></li>
		
			<li><a href="/tags/basics/" title="basics">basics<sup>11</sup></a></li>
		
			<li><a href="/tags/install/" title="install">install<sup>9</sup></a></li>
		
			<li><a href="/tags/linux/" title="linux">linux<sup>27</sup></a></li>
		
			<li><a href="/tags/minigui/" title="minigui">minigui<sup>13</sup></a></li>
		
			<li><a href="/tags/opengl/" title="opengl">opengl<sup>5</sup></a></li>
		
			<li><a href="/tags/other/" title="other">other<sup>5</sup></a></li>
		
			<li><a href="/tags/server/" title="server">server<sup>1</sup></a></li>
		
			<li><a href="/tags/shell/" title="shell">shell<sup>5</sup></a></li>
		
			<li><a href="/tags/vr/" title="vr">vr<sup>4</sup></a></li>
		
			<li><a href="/tags/window/" title="window">window<sup>11</sup></a></li>
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">我的链接</p>
    <ul>
      <li><i class="fa fa-github"></i> <a href="https://github.com/mingming-killer" target="_blank">GitHub</a></li>
      
        
          <li><i class="fa fa-analytics"></i> <a href="http://tongji.baidu.com/web/welcome/ico?s=fa045dbd45ffce238b146e00f91ba6a3" target="_blank">网站数据统计</a></li>
        
      
      <li><i class="fa fa-markdown-help"></i> <a href="http://zh.wikipedia.org/wiki/Markdown" target="_blank">Makrdown</a></li>
    </ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
      <li><i class="fa fa-book"></i> <a href="http://taoyuanxiaoqi.com" target="_blank">桃园小七的博客</a></li>
      <li><i class="fa fa-book"></i> <a href="https://dongka.github.io" target="_blank">Dongka的博客</a></li>
    </ul>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
<!--
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
-->

     <!-- this is defined in footer.styl, line holder -->
	<div class="line">
	</div>
     
<!--
	<div class="social-font clearfix">
		
		
		
		
		
		<a href="https://github.com/mingming-killer" target="_blank" title="github"></a>
		
        	         
	</div>
-->

		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/mingming-killer/Lightmoon" target="_blank" title="Lightmoon">Lightmoon</a> © 2021 
		
		<a href="http://www.light3moon.com" target="_blank" title="Mingming">Mingming</a>
		
		</p>

  <!-- baidu search verification -->
  
    <meta name="baidu-site-verification" content="w1BSX6yZ9k" />
  

  <!-- swiftype search verification -->
  

</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>






<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?fa045dbd45ffce238b146e00f91ba6a3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  </body>
</html>
